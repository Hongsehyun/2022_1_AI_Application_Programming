{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e9f4895",
   "metadata": {},
   "source": [
    "### 원본 그대로 사용하지 말고 따로 복사해서 사용할 것을 권장함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a34fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add libraries freely, if you need.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145b4c06",
   "metadata": {},
   "source": [
    "# 01. Linear Regression\n",
    "- Dataset: car_dataset.csv\n",
    "- Source: kaggle\n",
    "- Target: Price\n",
    "> You are required to model the price of cars with the available independent variables. It will be used by the management to understand how exactly the prices vary with the independent variables. They can accordingly manipulate the design of the cars, the business strategy etc. to meet certain price levels. Further, the model will be a good way for management to understand the pricing dynamics of a new market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac04994",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Dataset & 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd602b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) TO DO\n",
    "# 참고.\n",
    "# cateorical_vars = ['CompanyName', 'fueltype', 'aspiration', 'carbody', 'drivewheel', 'enginelocation', 'enginetype','cylindernumber']\n",
    "# numerical_vars = ['wheelbase','carlength', 'carwidth','curbweight','enginesize','boreratio', 'horsepower','fueleconomy']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de8220a",
   "metadata": {},
   "source": [
    "##### Deriving new features - \"fueleconomy\"  & \"carsrange\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a87b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_data['fueleconomy'] = (0.5*car_data['citympg']) + (0.5*car_data['highwaympg'])\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "\n",
    "sns.scatterplot(car_data['fueleconomy'],car_data['price'],hue=car_data['drivewheel'])\n",
    "plt.xlabel('Fuel Economy')\n",
    "plt.ylabel('Price')\n",
    "plt.show()\n",
    "\n",
    "# 'fueleconomy' has an obvious negative correlation with price and is significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef0971",
   "metadata": {},
   "source": [
    "### 3. Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab287ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f119e4f3",
   "metadata": {},
   "source": [
    "### 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abfa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = final_data.drop(['price'], axis=1)\n",
    "y = final_data['price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d4fce",
   "metadata": {},
   "source": [
    "### 5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c756ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# (c) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b199a04d",
   "metadata": {},
   "source": [
    "# 02. Logistic Regression\n",
    "\n",
    "- Dataset: fordA_train.csv, fordA_test.csv\n",
    "- Source: http://www.timeseriesclassification.com/description.php?Dataset=FordA\n",
    "- Target: Label (normal:1, abnormal:-1)\n",
    "> This data was originally used in a competition in the IEEE World Congress on Computational Intelligence, 2008. The classification problem is to diagnose whether a certain symptom exists or does not exist in an automotive subsystem. Each case consists of 500 measurements of engine noise and a classification. There are two separate problems: For FordA the Train and test data set were collected in typical operating conditions, with minimal noise contamination.\n",
    "- Notice: Do not download the file directly from the above-mentioned site. The provided file is a modified version of the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328b2ee2",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a972205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "train_df = pd.read_csv('./fordA_train.csv') # 경로 알아서 바꿀것\n",
    "test_df = pd.read_csv('./fordA_test.csv') # 경로 알아서 바꿀것\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697a5a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f1f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random_number = random.randint(0,500)\n",
    "\n",
    "plt.figure(figsize=(13,4))\n",
    "plt.plot(train_df.iloc[:,random_number])\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Detected Value by Sensor')\n",
    "plt.title('sensor #: {}'.format(random_number))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e13fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# (a-1) TO DO\n",
    "\n",
    "# Hint\n",
    "#X_train <- train_df 에서 맨 마지막 열만 제외\n",
    "#y_train <- train_df 에서의 맨 마지막 열\n",
    "\n",
    "#X_test <- test_df에서 맨 마지막 열만 제외\n",
    "#y_test <- test_df 에서의 맨 마지막 열\n",
    "\n",
    "#print(X_train.shape, y_train.shape, X_test.shape, y_test.shape) # 주석 해제하고 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bb5353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a-2) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8db8138",
   "metadata": {},
   "source": [
    "### 2. Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd4c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([-1,1])\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "\n",
    "for c in labels:\n",
    "    df = X_train[y_train == c].reset_index(drop=True)\n",
    "    time_t = random.randint(0, df.shape[0])\n",
    "    plt.scatter(range(0,500), df.iloc[time_t],\n",
    "                label='class = ' + str(int(c)) + ', time = ' + str(time_t), s=5)\n",
    "\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlabel('Sensor')\n",
    "plt.ylabel('Detected Value by Sensor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f39162",
   "metadata": {},
   "source": [
    "### 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa83e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers can often occur in process data, which requires robust normalization.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbscale = RobustScaler()\n",
    "X_train = rbscale.fit_transform(X_train)\n",
    "X_test = rbscale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b5104b",
   "metadata": {},
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295f64aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "base_model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "# (b) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31a932",
   "metadata": {},
   "source": [
    "### 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bb30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def conf_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data=cm,\n",
    "                      index=['Actual -1', 'Actual +1'],\n",
    "                      columns=['Predict -1', 'Predict +1'])\n",
    "    \n",
    "    # plotting the confusion matrix\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90bf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # (c-1) TO DO\n",
    "    \n",
    "    #TP = \n",
    "    #TN = \n",
    "    #FP = \n",
    "    #FN = \n",
    "    \n",
    "    #accuracy = \n",
    "    #precision = \n",
    "    #recall = \n",
    "    #f1_score =\n",
    "    \n",
    "    print('accuracy = ', accuracy)\n",
    "    print('precision = ', precision)\n",
    "    print('recall = ', recall)\n",
    "    print('f1_score = ', f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cea5fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c-2) TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa75331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-plot # scikitplot을 import 했을 때 load되지 않으면, 이 문장을 주석 해제하고 실행(설치)할 것.\n",
    "import scikitplot as skplt\n",
    "\n",
    "# (c-3) # TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9605da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "print('accuracy = ',accuracy_score(y_test, y_pred))\n",
    "print('precision = ',precision_score(y_test, y_pred))\n",
    "print('recall = ',recall_score(y_test, y_pred))\n",
    "print('f1_score = ',f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31b427b",
   "metadata": {},
   "source": [
    "# 03. Support Vector Machine\n",
    "- Dataset: breast_cancer_dataset.csv\n",
    "- Source: UCI Machine Learning repository\n",
    "- Target: Diagnosis (M=malignant, B=benign)\n",
    "> Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.\n",
    "- For more information, check this website: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d03486",
   "metadata": {},
   "source": [
    "### 1. Import Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7664603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "\n",
    "data = pd.read_csv('./breast_cancer_dataset.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04f043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.shape\n",
    "#data.info()\n",
    "#data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d818b97e",
   "metadata": {},
   "source": [
    "### 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc63a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['diagnosis'] = pd.get_dummies(data['diagnosis'], drop_first=True)\n",
    "data['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99112869",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['id','Unnamed: 32','diagnosis'], axis=1)\n",
    "y = data['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbc14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check correlation between the variables\n",
    "plt.figure(figsize=(18,12))\n",
    "sns.heatmap(X.corr(), vmin=0.85, vmax=1, annot=True, cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9586a111",
   "metadata": {},
   "source": [
    "### 3. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039153bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "# TO DO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bc1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define evaluation function\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "def print_model_score(actual, pred):\n",
    "    print(confusion_matrix(actual, pred))\n",
    "    print('accuracy: %.3f' % accuracy_score(actual, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d14bf",
   "metadata": {},
   "source": [
    "### 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b030e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_model = LinearSVC(loss='hinge', random_state=0)\n",
    "\n",
    "# TO DO\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a696c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "# (c-1) TO DO\n",
    "\n",
    "\n",
    "# (c-2) TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc9045a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def plot_roc_curve(fpr, tpr):\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(fpr, tpr, linewidth=2)\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "\n",
    "    plt.xlabel('FPR (1-specificity)')\n",
    "    plt.ylabel('TPR (sensitivity)')\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a3d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) TO DO\n",
    "\n",
    "# Hint\n",
    "# 1. fpr, tpr, thresholds = roc_curve(테스트 데이터셋의 실제 label, 예측한 label)\n",
    "# 2. plot_roc_curve(fpr, tpr)\n",
    "# 3. print('AUC score = ', roc_auc_score(테스트 데이터셋의 실제 label, 예측한 label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f72208",
   "metadata": {},
   "source": [
    "# 04. Decision Tree & Ensemble Learning\n",
    "\n",
    "- Dataset: fordA_train.csv, fordA_test.csv\n",
    "- Target: Label (normal:1, abnormal:-1)\n",
    "- Notice: Same dataset used for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3267ec60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "\n",
    "train_df = pd.read_csv('./fordA_train.csv') # 경로 알아서 바꿀것\n",
    "test_df = pd.read_csv('./fordA_test.csv') # 경로 알아서 바꿀것\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c17c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4432e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train <- train_df 에서 맨 마지막 열만 제외\n",
    "#y_train <- train_df 에서의 맨 마지막 열\n",
    "\n",
    "#X_test <- test_df에서 맨 마지막 열만 제외\n",
    "#y_test <- test_df 에서의 맨 마지막 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b50df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers can often occur in process data, which requires robust normalization.\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "rbscale = RobustScaler()\n",
    "X_train = rbscale.fit_transform(X_train)\n",
    "X_test = rbscale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273a03c7",
   "metadata": {},
   "source": [
    "### Funtions used for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914603f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def conf_matrix(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data=cm,\n",
    "                      index=['Actual -1', 'Actual +1'],\n",
    "                      columns=['Predict -1', 'Predict +1'])\n",
    "    \n",
    "    # plotting the confusion matrix\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a0736",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # (c-1) TO DO\n",
    "    \n",
    "    #TP = \n",
    "    #TN = \n",
    "    #FP = \n",
    "    #FN = \n",
    "    \n",
    "    #accuracy = \n",
    "    #precision = \n",
    "    #recall = \n",
    "    #f1_score =\n",
    "    \n",
    "    print('accuracy = ', accuracy)\n",
    "    print('precision = ', precision)\n",
    "    print('recall = ', recall)\n",
    "    print('f1_score = ', f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59aef07",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110548e0",
   "metadata": {},
   "source": [
    "__Decision Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8710cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# (a) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0183dc",
   "metadata": {},
   "source": [
    "__Bagging__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466fae9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bagging = BaggingClassifier(base_estimator = DecisionTreeClassifier(),\n",
    "                            n_estimators=10, # 10개의 tree\n",
    "                            random_state=0,\n",
    "                            verbose=1) # 학습 과정 표시\n",
    "\n",
    "# TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76fc19c",
   "metadata": {},
   "source": [
    "__Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826247db",
   "metadata": {},
   "source": [
    "__Boosting__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1b5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train, random_state=0)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687d9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(max_depth=10,\n",
    "                              learning_rate=0.1,\n",
    "                              n_estimators=100,\n",
    "                              objective='binary:logistic')\n",
    "xgb_model.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "              eval_metric=['auc'],\n",
    "              verbose=False\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (d) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50fd5b4",
   "metadata": {},
   "source": [
    "# 05. Clustering\n",
    "- Dataset: wine_clustering.csv\n",
    "- Source: UCI Machine Learning repository\n",
    "- Target: \n",
    "- For more information, check this website: https://archive.ics.uci.edu/ml/datasets/wine\n",
    ">These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines.\n",
    "- Others\n",
    "https://www.kaggle.com/questions-and-answers/122539"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbb54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv('./wine_clustering.csv')\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a2d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35878ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.boxplot(wine_data.values, labels=wine_data.columns)\n",
    "plt.title('Feature boxplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f82d78",
   "metadata": {},
   "source": [
    "### data normalizaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad904c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scale = StandardScaler()\n",
    "scaled_data = scale.fit_transform(wine_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28984042",
   "metadata": {},
   "source": [
    "### visualization using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f1e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(2)\n",
    "pca_data = pca.fit_transform(scaled_data)\n",
    "#pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114760f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) TO DO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e1c33",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f6ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "within_cluster_ss = []\n",
    "for i in range(1, 5+1):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=0)\n",
    "    kmeans.fit(scaled_data)\n",
    "    ss = kmeans.inertia_\n",
    "    within_cluster_ss.append(ss)\n",
    "    \n",
    "cluster_num = range(1, 5+1)\n",
    "plt.plot(cluster_num, within_cluster_ss, marker='o')\n",
    "plt.title('The Elbow Method Plot')\n",
    "plt.xlabel('# of cluster')\n",
    "plt.ylabel('within cluster sum of square')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a362cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example_code: K means clustering, define k as '2'\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans_model = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "pd.Series(kmeans_model).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6f6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b)\n",
    "# (b-1) TO DO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d950ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b-2) TO DO\n",
    "\n",
    "# Hint\n",
    "# 1. 바로 위의 코드를 참고하여 구현\n",
    "# 2. centroid를 얻기 위해 centroid = kmeans.cluster_centers_ 실행\n",
    "# 3. centroid의 principal component 를 얻기 위해 centroid_pca = pca.transform(centroid) 실행\n",
    "# 4. 'pca_data'와 'centroid_pca'를 활용해 scatter plot 을 visualizaiton\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516ff32",
   "metadata": {},
   "source": [
    "### Extra - Classifying random data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf673aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# generate some random cluster data\n",
    "X, y = make_blobs(random_state=170, n_samples=500, centers=5)\n",
    "random_generator = np.random.RandomState(70)\n",
    "\n",
    "# transform the data to be stretched\n",
    "transform = random_generator.normal(size=(2,2))\n",
    "X = np.dot(X, transform)\n",
    "\n",
    "# plot\n",
    "plt.scatter(X[:,0], X[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3169ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=5)\n",
    "y_pred = kmeans.fit_predict(X)\n",
    "\n",
    "# plot the cluster assignments and cluster centers\n",
    "plt.scatter(X[:,0], X[:,1], c=y_pred)\n",
    "plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], marker='x', c='red')\n",
    "plt.title('Clustered Data using k-means clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8203b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (c) TO DO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
